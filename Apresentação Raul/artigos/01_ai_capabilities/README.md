# 01_ai_capabilities — Artigos Selecionados

> Critério: 2024-2026, alta citação ou labs tier-1 (Google, OpenAI, Microsoft, DeepMind)

---

## Sparks of Artificial General Intelligence: Early Experiments with GPT-4

- **Autores:** Sébastien Bubeck et al. (Microsoft Research, 14 autores)
- **Ano/Venue:** 2023 — arXiv:2303.12712
- **Citações:** ~10.000+ (um dos mais citados de 2023, referência obrigatória)
- **PDF:** https://arxiv.org/pdf/2303.12712
- **Resumo (PT-BR):** O paper da Microsoft Research que inaugurou o debate sobre AGI ao explorar sistematicamente as capacidades do GPT-4 em matemática, programação, medicina, direito, visão e raciocínio. Demonstra que o modelo resolve tarefas novas e difíceis sem necessidade de instruções especializadas, superando benchmarks humanos em diversas disciplinas. Os autores concluem que GPT-4 pode ser considerado um precursor incompleto de AGI.
- **Relevância para a aula:** Ponto de virada histórico — ilustra o salto qualitativo da IA a partir de 2023 e serve de âncora para a narrativa de "antes e depois" da IA moderna. Excelente para abrir a aula mostrando o que mudou.

---

## GPT-4 Technical Report

- **Autores:** OpenAI
- **Ano/Venue:** 2023 — arXiv:2303.08774 (publicado e atualizado em 2024)
- **Citações:** ~5.000+ (referência primária de todos os trabalhos sobre GPT-4)
- **PDF:** https://arxiv.org/pdf/2303.08774
- **Resumo (PT-BR):** Relatório técnico oficial do GPT-4, descrevendo a arquitetura multimodal capaz de processar texto e imagens para produzir saídas textuais. Apresenta resultados em exames profissionais humanos: aprovação no bar exam (top 10%), LSAT, SAT e GRE. Introduz o conceito de avaliação de modelos por meio de benchmarks de competência humana em vez de benchmarks de NLP tradicionais.
- **Relevância para a aula:** Referência canônica para mostrar que a IA de 2023-2024 já supera especialistas humanos em provas padronizadas — argumento poderoso para reguladores e engenheiros céticos sobre as capacidades reais da IA.

---

## Gemini 1.5: Unlocking Multimodal Understanding Across Millions of Tokens of Context

- **Autores:** Google DeepMind (team report)
- **Ano/Venue:** Março 2024 — arXiv:2403.05530
- **Citações:** ~800+ (lab tier-1: Google DeepMind)
- **PDF:** https://arxiv.org/pdf/2403.05530
- **Resumo (PT-BR):** Relatório técnico do Gemini 1.5, modelo multimodal altamente eficiente capaz de processar milhões de tokens de contexto — o equivalente a horas de vídeo, áudio ou centenas de documentos longos simultaneamente. O modelo alcança recall quasi-perfeito em tarefas de recuperação de informação em contextos longos e supera ou iguala o Gemini 1.0 Ultra em benchmarks gerais.
- **Relevância para a aula:** Ilustra a capacidade de análise de documentos regulatórios longos (contratos, relatórios técnicos, normas ABNT, RTMs) — muito relevante para reguladores que lidam com grandes volumes de texto normativo.

---

## AI Achieves Gold-Medal Standard at International Mathematical Olympiad

- **Autores:** Google DeepMind
- **Ano/Venue:** Julho 2025 — Blog oficial DeepMind + Nature (2025)
- **Citações:** Lab tier-1: Google DeepMind; publicado na Nature em 2025
- **PDF/URL:** https://deepmind.google/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/
- **Resumo (PT-BR):** O Gemini com Deep Think resolveu 5 dos 6 problemas da Olimpíada Internacional de Matemática de 2025, atingindo nível de medalha de ouro com 35 pontos — dentro do limite de 4,5 horas da competição. Em 2024, AlphaProof tinha conseguido apenas nível prata (4/6 problemas). Representa o marco mais recente e impactante em raciocínio matemático formal por IA.
- **Relevância para a aula:** Serve como ilustração poderosa do salto de capacidade — se a IA consegue resolver olimpíadas de matemática em nível de ouro, o que ela pode fazer com análise de dados de distribuição de gás? Cria impacto emocional imediato no público.

---

## OpenAI o1 System Card

- **Autores:** OpenAI
- **Ano/Venue:** Dezembro 2024 — arXiv:2412.16720
- **Citações:** Lab tier-1: OpenAI (documento de sistema oficial)
- **PDF:** https://arxiv.org/abs/2412.16720
- **Resumo (PT-BR):** Documentação técnica e de segurança do modelo o1, que usa aprendizado por reforço em larga escala para raciocinar por cadeia de pensamento antes de responder. O o1 supera especialistas humanos com PhD no benchmark GPQA (química, física, biologia) e atingiu 90,8% no MMLU. Representa a transição da IA de "recuperação de padrões" para "raciocínio deliberativo".
- **Relevância para a aula:** Mostra a geração atual de IA como "pensadora", não apenas geradora de texto — o modelo "pensa" antes de responder, o que é análogo ao processo de um especialista. Relevante para convencer que IA pode ser parceira em análise técnica.

---

## The 2024 AI Index Report (Stanford HAI)

- **Autores:** Stanford Human-Centered AI Institute (HAI)
- **Ano/Venue:** 2024 — arXiv:2405.19522 / Stanford HAI
- **Citações:** Referência institucional de prestígio; amplamente citado em policy e academia
- **PDF:** https://arxiv.org/abs/2405.19522
- **Resumo (PT-BR):** Relatório anual mais abrangente sobre o estado da IA, cobrindo avanços técnicos, percepção pública, dinâmicas geopolíticas, custos de treinamento, paisagem de IA responsável e impacto em ciência e medicina. Em 2024, o investimento privado americano em IA atingiu US$ 109 bilhões. Os EUA lideram com 40 modelos notáveis versus 15 da China.
- **Relevância para a aula:** Fonte de dados e estatísticas para contextualizar o boom da IA em 2024 — útil para slides de "onde estamos" e para responder perguntas sobre tendências globais com autoridade acadêmica.
